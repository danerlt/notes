# LlamaIndex ç´¢å¼•

ä¸€ä¸ªRAGç³»ç»Ÿçš„æµç¨‹å¤§è‡´å¦‚å›¾ï¼š

![image-20240426011357639](https://danerlt-1258802437.cos.ap-chongqing.myqcloud.com/images/image-20240426011357639.png)

æœ¬æ–‡ä¸»è¦å…³æ³¨å…¶ä¸­çš„æ£€ç´¢éƒ¨åˆ†ã€‚ä½¿ç”¨çš„æ¡†æ¶æ˜¯ [llama_index](https://www.llamaindex.ai/) ã€‚åœ¨ä¸€ä¸ªRAGç³»ç»Ÿä¸­ï¼Œåœ¨åŠ è½½æ–‡æ¡£ä¹‹åä¼šå¾—åˆ°ä¸€ä¸ª Document åˆ—è¡¨ (æˆ–è€…Node åˆ—è¡¨, Document ç»§æ‰¿Â·è‡ªTextNodeï¼Œä¸€èˆ¬æƒ…å†µä¸‹ä½¿ç”¨çš„éƒ½æ˜¯TextNode)ï¼Œç„¶åå¯¹è¿™äº› Document åˆ—è¡¨åˆ›å»ºç´¢å¼•ï¼ˆIndexï¼‰æ¥æ–¹ä¾¿æ£€ç´¢ã€‚



## Document å¯¹è±¡å’ŒNodeå¯¹è±¡

é¦–å…ˆæˆ‘ä»¬è¦æ¥çœ‹ä¸€ä¸‹ Documentå¯¹è±¡ å’Œ TextNodeå¯¹è±¡æ˜¯ä»€ä¹ˆæ ·å­ã€‚å…¶æºç åœ¨`llama_index\core\schema.py`ä¸­ï¼š

```mermaid
classDiagram
 
  class BaseComponent {
    class_name() str
    dict() Dict[str, Any]
    from_dict(data: Dict[str, Any]) Self
    from_json(data_str: str) Self
    json() str
    to_dict() Dict[str, Any]
    to_json() str
  }
  class BaseNode {
    child_nodes
    embedding : Optional[List[float]]
    excluded_embed_metadata_keys : List[str]
    excluded_llm_metadata_keys : List[str]
    extra_info
    hash
    id_ : str
    metadata : Dict[str, Any]
    next_node
    node_id
    parent_node
    prev_node
    ref_doc_id
    relationships : Dict[NodeRelationship, RelatedNodeType]
    source_node
  }
  class Document {
    doc_id
    id_ : str
  }
  class TextNode {
    end_char_idx : Optional[int]
    hash
    metadata_seperator : str
    metadata_template : str
    node_info
    start_char_idx : Optional[int]
    text : str
    text_template : str

  }
  BaseNode --|> BaseComponent
  TextNode --|> BaseNode
  Document --|> TextNode
```

å…¶ä¸­ `BaseComponent` æä¾›äº†ä¸€ä¸ªå¯¹è±¡å’Œjsonï¼Œå­—å…¸äº’ç›¸è½¬æ¢çš„æ–¹æ³•ã€‚`Document` ç»§æ‰¿è‡ª `TextNode`ï¼Œ`TextNode`ç»§æ‰¿è‡ª`BaseNode`ï¼Œ`BaseNode`ç»§æ‰¿è‡ª`BaseComponent`ã€‚å…¶ä¸­ `BaseComponent` æä¾›äº†ä¸€ä¸ªå¯¹è±¡å’Œjsonï¼Œå­—å…¸äº’ç›¸è½¬æ¢çš„æ–¹æ³•ã€‚

`BaseNode`ä¸­çš„å­—æ®µè¯´æ˜ï¼š

-   id_: Node çš„å”¯ä¸€Idï¼Œé»˜è®¤æƒ…å†µä½¿ç”¨uuid.uuid4ç”Ÿæˆçš„ï¼Œ**éœ€è¦æ³¨æ„çš„æ˜¯,è¿™ä¸ªå­—æ®µä¸€èˆ¬ä¸ç›´æ¥ä½¿ç”¨ï¼Œè€Œæ˜¯ä½¿ç”¨`node_id`è¿™ä¸ªproperty**

-   embedding: Nodeå¯¹åº”çš„embeddingå­—æ®µï¼Œæ˜¯ä¸€ä¸ªfloatåˆ—è¡¨ï¼Œé»˜è®¤æƒ…å†µä¸º`None`

-   metadata:  å…ƒæ•°æ®ï¼Œæ˜¯ä¸€ä¸ªå­—å…¸

-   excluded_embed_metadata_keysï¼šåœ¨embeddingæ—¶ç”¨æ¥æ’é™¤metadataçš„keyåˆ—è¡¨

-   excluded_llm_metadata_keys: åœ¨llmè°ƒç”¨æ—¶ç”¨æ¥æ’é™¤metadataçš„keyåˆ—è¡¨

-   relationshipsï¼šä¸€ä¸ªå­—å…¸ï¼Œç”¨æ¥ä¿å­˜å…¶ä»–Nodeå’Œå½“å‰Nodeçš„å…³ç³»ï¼Œæœ‰`Source`,`PREVIOUS`,`NEXT`,`PARENT`,`CHILD`ç­‰å…³ç³»ã€‚`Source`è¡¨ç¤ºæ˜¯å½“å‰ Nodeï¼Œ`PREVIOUS`è¡¨ç¤ºæ˜¯å½“å‰ Node çš„å‰ä¸€ä¸ªï¼Œ`NEXT`è¡¨ç¤ºæ˜¯å½“å‰Nodeçš„ä¸‹ä¸€ä¸ªï¼Œ`PARENT`æ˜¯å½“å‰Nodeçš„çˆ¶èŠ‚ç‚¹ï¼Œ`CHILD`è¡¨ç¤ºæ˜¯å½“å‰èŠ‚ç‚¹çš„å­èŠ‚ç‚¹ã€‚






## ä»€ä¹ˆæ˜¯llama_indexä¸­çš„ç´¢å¼•ï¼ˆIndexï¼‰

>   åœ¨ LlamaIndex æœ¯è¯­ä¸­ï¼Œ `Index` æ˜¯ç”± `Document` å¯¹è±¡ç»„æˆçš„æ•°æ®ç»“æ„ï¼Œæ—¨åœ¨æ”¯æŒ LLM è¿›è¡ŒæŸ¥è¯¢ã€‚

LlamaIndex æä¾›äº†å‡ ç§ä¸åŒçš„ç´¢å¼•ç±»å‹ã€‚æˆ‘ä»¬å°†åœ¨è¿™é‡Œä»‹ç»ä¸¤ä¸ªæœ€å¸¸è§çš„ã€‚

-   Vector Store Index(å‘é‡å­˜å‚¨ç´¢å¼•)ï¼š`VectorStoreIndex` æ˜¯æœ€å¸¸è§çš„ç´¢å¼•ç±»å‹ã€‚å®ƒæ¥å— Document åˆ—è¡¨ç„¶åå°†å…¶splitæˆNodes.



## LlamaIndex ç´¢å¼•æ ·ä¾‹

ä½¿ç”¨llama_indexåˆ›å»ºç´¢å¼•çš„æ ·ä¾‹ä»£ç å¦‚ä¸‹ï¼š

```python
import logging
from urllib.parse import quote_plus

import qdrant_client
from llama_index.core import SimpleDirectoryReader, StorageContext, VectorStoreIndex
from llama_index.core.indices.vector_store import VectorIndexRetriever
from llama_index.core.storage.docstore.postgres_docstore import PostgresDocumentStore
from llama_index.storage.docstore.mongodb import MongoDocumentStore
from llama_index.storage.index_store.redis.base import RedisIndexStore
from llama_index.vector_stores.qdrant import QdrantVectorStore
from redis import Redis

from commmon.config import config

logger = logging.getLogger("test")

def log_document(document):
    logger.info(f"{document.doc_id=}, {document.ref_doc_id=}")
    logger.info(f"relationships: {document.relationships}")
    logger.info(f"document: {vars(document)}")
    
def test_create_index():
    # åŠ è½½æ–‡æ¡£
    # ä¸€ä¸ªæ–‡ä»¶å¯¹åº”å¤šä¸ªdocumentå¯¹è±¡ node_idç­‰äºdoc_idç­‰äºid_
    #
     documents = SimpleDirectoryReader(input_files=["test.md"], file_extractor={".md": MarkdownReader(remove_images=False, remove_hyperlinks=False)}).load_data()
    logger.info(f"åŠ è½½æ–‡æ¡£æˆåŠŸï¼Œå…±{len(documents)}ä¸ªæ–‡æ¡£")
    for document in documents:
        log_document(document)
        
    # å®šä¹‰docså­˜å‚¨
    # uriæ ¼å¼å¦‚ä¸‹ï¼š"mongodb://mongo_user:mongo_password@mongo_host:mongo_port
    mongo_db_uri = "mongodb://mongo_user:mongo_password@mongo_host:mongo_port"
    docs_store = MongoDocumentStore.from_uri(mongo_db_uri, db_name="test")

    # å®šä¹‰vectorå­˜å‚¨
    client = qdrant_client.QdrantClient(
        host=config.QDRANT_HOST,
        port=config.QDRANT_PORT,
        https=config.QDRANT_HTTPS,
        # set API KEY for Qdrant Cloud
        # api_key="<qdrant-api-key>",
        api_key=config.QDRANT_API_KEY,
    )
    vector_store = QdrantVectorStore(client=client,
                                     batch_size=64,
                                     parallel=10,
                                     max_retries=3,
                                     enable_hybrid=False,
                                     collection_name="test")

    # å®šä¹‰indexå­˜å‚¨
    # uriæ ¼å¼å¦‚ä¸‹ï¼š"redis://:redis_password@redis_host:redis_port/redis_db"
    redis_client = Redis(host=config.REDIS_HOST,
                         port=config.REDIS_PORT,
                         password=config.REDIS_PASSWORD,
                         db=config.REDIS_DB)
    index_sotre = RedisIndexStore.from_redis_client(redis_client, namespace="test")

    # åˆ›å»ºstorage context
    storage_context = StorageContext.from_defaults(docstore=docs_store,
                                                   vector_store=vector_store,
                                                   index_store=index_sotre)

    # æ„å»ºç´¢å¼•
    index = VectorStoreIndex.from_documents(
        documents,
        storage_context=storage_context,
        store_nodes_override=True,  # å­˜å‚¨nodesæ—¶æ˜¯å¦è¦†ç›–
    )
    # index.index_struct  :  IndexDict(index_id="xxx", nodes_dict={"node_id":"node_id"}) index_id 111 -> node_ids: [1,2,3,4]
    logger.info("æ„å»ºç´¢å¼•æˆåŠŸ")
    retriever = index.as_retriever(similarity_top_k=10)
    query = "This is a test query text"
    response = retriever.retrieve(query)
    logger.info(f"æ£€ç´¢ç»“æœï¼š{len(response)=")
    logger.info(f"æ£€ç´¢ç»“æœï¼š{response[0]=}")
```

`test.md`å†…å®¹ä½¿ç”¨çš„æ˜¯[Langchain-chatchat](https://github.com/chatchat-space/Langchain-Chatchat)é¡¹ç›®çš„README.mdæ–‡ä»¶ã€‚

è¯»å–å®Œ`documents`åˆ—è¡¨çš„é•¿åº¦ä¸º`21`,å…¶ä¸­ç¬¬ä¸€ä¸ªdocumentå†…å®¹å¦‚ä¸‹ï¼š

```python
{'id_': 'd8831dcb-6840-48fa-a222-8f82aab2f163',
 'embedding': None,
 'metadata': {'file_path': 'test.md',
  'file_name': 'test.md',
  'file_size': 8503,
  'creation_date': '2024-05-06',
  'last_modified_date': '2024-04-30'},
 'excluded_embed_metadata_keys': ['file_name',
  'file_type',
  'file_size',
  'creation_date',
  'last_modified_date',
  'last_accessed_date'],
 'excluded_llm_metadata_keys': ['file_name',
  'file_type',
  'file_size',
  'creation_date',
  'last_modified_date',
  'last_accessed_date'],
 'relationships': {},
 'text': '\n\n\n![](img/logo-long-chatchat-trans-v2.png)\r\n\r\ní ¼í¼ [READ THIS IN ENGLISH](README_en.md)\r\ní ¼í¼ [æ—¥æœ¬èªã§èª­ã‚€](README_ja.md)\r\n\r\ní ½í³ƒ **LangChain-Chatchat** (åŸ Langchain-ChatGLM)\r\n\r\nåŸºäº ChatGLM ç­‰å¤§è¯­è¨€æ¨¡å‹ä¸ Langchain ç­‰åº”ç”¨æ¡†æ¶å®ç°ï¼Œå¼€æºã€å¯ç¦»çº¿éƒ¨ç½²çš„æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)å¤§æ¨¡å‹çŸ¥è¯†åº“é¡¹ç›®ã€‚\r\n\r\n',
 'start_char_idx': None,
 'end_char_idx': None,
 'text_template': '{metadata_str}\n\n{content}',
 'metadata_template': '{key}: {value}',
 'metadata_seperator': '\n',
 'class_name': 'Document'}
```





## æ„å»ºç´¢å¼•æºç åˆ†æ



`form_documents`ä»£ç å¦‚ä¸‹ï¼š

```python
    @classmethod
    def from_documents(
        cls: Type[IndexType],
        documents: Sequence[Document],
        storage_context: Optional[StorageContext] = None,
        show_progress: bool = False,
        callback_manager: Optional[CallbackManager] = None,
        transformations: Optional[List[TransformComponent]] = None,
        # deprecated
        service_context: Optional[ServiceContext] = None,
        **kwargs: Any,
    ) -> IndexType:
        """Create index from documents.

        Args:
            documents (Optional[Sequence[BaseDocument]]): List of documents to
                build the index from.

        """
        storage_context = storage_context or StorageContext.from_defaults()
        docstore = storage_context.docstore
        callback_manager = (
            callback_manager
            or callback_manager_from_settings_or_context(Settings, service_context)
        )
        transformations = transformations or transformations_from_settings_or_context(
            Settings, service_context
        )

        with callback_manager.as_trace("index_construction"):
            for doc in documents:
                docstore.set_document_hash(doc.get_doc_id(), doc.hash)

            nodes = run_transformations(
                documents,  # type: ignore
                transformations,
                show_progress=show_progress,
                **kwargs,
            )

            return cls(
                nodes=nodes,
                storage_context=storage_context,
                callback_manager=callback_manager,
                show_progress=show_progress,
                transformations=transformations,
                service_context=service_context,
                **kwargs,
            )
```

æœ¬ä¾‹ä¸­`transformations`åˆ—è¡¨ä¸ºç©ºï¼Œ`nodes`å’Œ`documents`æ˜¯åŒä¸€ä¸ªåˆ—è¡¨ã€‚

è¿™ä¸ªæ–¹æ³•é¦–å…ˆä¼šè°ƒç”¨`set_document_hash`å°† Document çš„ hash å€¼ å­˜å‚¨åˆ° docstore ä¸­ã€‚åœ¨æœ¬ä¾‹ä¸­ä¼šå°† doc_hash å†™å…¥åˆ°MongoDBä¸­çš„`docstore/metadata` ä¸­ã€‚

![image-20240506090622812](https://danerlt-1258802437.cos.ap-chongqing.myqcloud.com/images/image-20240506090622812.png)



ç„¶åæ‰§è¡Œ `run_transformations` åšæ–‡æ¡£æ‹†åˆ†ï¼Œå…ƒæ•°æ®æå–ç­‰å·¥ä½œå¾—åˆ°å¯¹åº”çš„`nodes`ï¼Œå…·ä½“æ‰§è¡Œäº†å“ªäº›æ˜¯æ ¹æ®`transformations`å‚æ•°å†³å®šçš„ã€‚é»˜è®¤æƒ…å†µä¸‹`transformations`æ˜¯åªæœ‰ä¸€ä¸ªå…ƒç´ çš„åˆ—è¡¨ï¼Œå…¶ä¸­çš„å…ƒç´ æ˜¯`SentenceSplitter`ç±»çš„å®ä¾‹ã€‚`transformations`ç›¸å…³ä»£ç å¦‚ä¸‹ï¼š

```python
transformations = transformations or transformations_from_settings_or_context(
    Settings, service_context
)
    
def transformations_from_settings_or_context(
    settings: _Settings, context: Optional["ServiceContext"]
) -> List[TransformComponent]:
    """Get settings from either settings or context."""
    if context is not None:
        return context.transformations

    return settings.transformations  


@dataclass
class _Settings:
    """Settings for the Llama Index, lazily initialized."""

    # lazy initialization
    _llm: Optional[LLM] = None
    _embed_model: Optional[BaseEmbedding] = None
    _callback_manager: Optional[CallbackManager] = None
    _tokenizer: Optional[Callable[[str], List[Any]]] = None
    _node_parser: Optional[NodeParser] = None
    _prompt_helper: Optional[PromptHelper] = None
    _transformations: Optional[List[TransformComponent]] = None

    # ---- Node parser ----
    @property
    def node_parser(self) -> NodeParser:
        """Get the node parser."""
        if self._node_parser is None:
            self._node_parser = SentenceSplitter()

        if self._callback_manager is not None:
            self._node_parser.callback_manager = self._callback_manager

        return self._node_parser


    # ---- Transformations ----
    @property
    def transformations(self) -> List[TransformComponent]:
        """Get the transformations."""
        if self._transformations is None:
            self._transformations = [self.node_parser]
        return self._transformations


# Singleton
Settings = _Settings()
```

æœ€åä¼šå®ä¾‹åŒ–`VectorStoreIndex`ç±»ï¼Œä¼šè°ƒç”¨`VectorStoreIndex`ç±»çš„`__init__`æ–¹æ³•ï¼Œè¿™ä¸ªæ—¶å€™ nodes æœ‰å€¼ï¼Œobjects å’Œ index_structéƒ½ä¸º Noneï¼š

```python
class VectorStoreIndex(BaseIndex[IndexDict]):
    """Vector Store Index.

    Args:
        use_async (bool): Whether to use asynchronous calls. Defaults to False.
        show_progress (bool): Whether to show tqdm progress bars. Defaults to False.
        store_nodes_override (bool): set to True to always store Node objects in index
            store and document store even if vector store keeps text. Defaults to False
    """

    index_struct_cls = IndexDict

    def __init__(
        self,
        nodes: Optional[Sequence[BaseNode]] = None,
        # vector store index params
        use_async: bool = False,
        store_nodes_override: bool = False,
        embed_model: Optional[EmbedType] = None,
        insert_batch_size: int = 2048,
        # parent class params
        objects: Optional[Sequence[IndexNode]] = None,
        index_struct: Optional[IndexDict] = None,
        storage_context: Optional[StorageContext] = None,
        callback_manager: Optional[CallbackManager] = None,
        transformations: Optional[List[TransformComponent]] = None,
        show_progress: bool = False,
        # deprecated
        service_context: Optional[ServiceContext] = None,
        **kwargs: Any,
    ) -> None:
        """Initialize params."""
        self._use_async = use_async
        self._store_nodes_override = store_nodes_override
        self._embed_model = (
            resolve_embed_model(embed_model, callback_manager=callback_manager)
            if embed_model
            else embed_model_from_settings_or_context(Settings, service_context)
        )

        self._insert_batch_size = insert_batch_size
        super().__init__(
            nodes=nodes,
            index_struct=index_struct,
            service_context=service_context,
            storage_context=storage_context,
            show_progress=show_progress,
            objects=objects,
            callback_manager=callback_manager,
            transformations=transformations,
            **kwargs,
        )
```

è¿™ä¸ªæ–¹æ³•é‡Œé¢é¦–å…ˆä¼šè·å–`embedding model`ï¼Œç„¶åæ‰§è¡Œçˆ¶ç±»`BaseIndex`çš„`__init__`æ–¹æ³•ã€‚

```python
class BaseIndex(Generic[IS], ABC):
    """Base LlamaIndex.

    Args:
        nodes (List[Node]): List of nodes to index
        show_progress (bool): Whether to show tqdm progress bars. Defaults to False.
        service_context (ServiceContext): Service context container (contains
            components like LLM, Embeddings, etc.).

    """

    index_struct_cls: Type[IS]

    def __init__(
        self,
        nodes: Optional[Sequence[BaseNode]] = None,
        objects: Optional[Sequence[IndexNode]] = None,
        index_struct: Optional[IS] = None,
        storage_context: Optional[StorageContext] = None,
        callback_manager: Optional[CallbackManager] = None,
        transformations: Optional[List[TransformComponent]] = None,
        show_progress: bool = False,
        # deprecated
        service_context: Optional[ServiceContext] = None,
        **kwargs: Any,
    ) -> None:
        """Initialize with parameters."""
        if index_struct is None and nodes is None and objects is None:
            raise ValueError("One of nodes, objects, or index_struct must be provided.")
        if index_struct is not None and nodes is not None:
            raise ValueError("Only one of nodes or index_struct can be provided.")
        # This is to explicitly make sure that the old UX is not used
        if nodes is not None and len(nodes) >= 1 and not isinstance(nodes[0], BaseNode):
            if isinstance(nodes[0], Document):
                raise ValueError(
                    "The constructor now takes in a list of Node objects. "
                    "Since you are passing in a list of Document objects, "
                    "please use `from_documents` instead."
                )
            else:
                raise ValueError("nodes must be a list of Node objects.")

        self._storage_context = storage_context or StorageContext.from_defaults()
        # deprecated
        self._service_context = service_context

        self._docstore = self._storage_context.docstore
        self._show_progress = show_progress
        self._vector_store = self._storage_context.vector_store
        self._graph_store = self._storage_context.graph_store
        self._callback_manager = (
            callback_manager
            or callback_manager_from_settings_or_context(Settings, service_context)
        )

        objects = objects or []
        self._object_map = {obj.index_id: obj.obj for obj in objects}
        for obj in objects:
            obj.obj = None  # clear the object to avoid serialization issues

        with self._callback_manager.as_trace("index_construction"):
            if index_struct is None:
                nodes = nodes or []
                index_struct = self.build_index_from_nodes(
                    nodes + objects  # type: ignore
                )
            self._index_struct = index_struct
            self._storage_context.index_store.add_index_struct(self._index_struct)

        self._transformations = (
            transformations
            or transformations_from_settings_or_context(Settings, service_context)
        )
```

è¿™ä¸ªæ–¹æ³•é¦–å…ˆä¼šå¯¹ nodes, index_struct, objectså‚æ•°åšéªŒè¯ï¼Œç„¶åä» storage_context ä¸­è·å–å„ç§storeã€‚å› ä¸º objects ä¸ºNoneï¼Œæ¥ç€å…³äºobjectçš„å¾ªç¯ä¸ä¼šæ‰§è¡Œã€‚æ¥ç€å°±æ˜¯è°ƒç”¨`build_index_from_nodes`æ–¹æ³•æ„å»ºç´¢å¼•ï¼Œç„¶åè°ƒç”¨` self._storage_context.index_store.add_index_struct(self._index_struct)`å°†`index_struct`ä»“å‚¨åˆ°`index_store`ä¸­ã€‚

å°† nodes ä¸­çš„æ–‡æœ¬æ‰§è¡Œå‘é‡åŒ–ï¼Œä¿å­˜åˆ°å‘é‡æ•°æ®åº“(æœ¬æ¬¡ç¤ºä¾‹ä¸ºQdrantï¼‰ï¼Œè¿˜æœ‰å°†æ–‡æ¡£ä¿å­˜åˆ°doc_store(æœ¬æ¬¡ç¤ºä¾‹ä¸ºMongoDBï¼‰ä¸­éƒ½æ˜¯åœ¨è¿™ä¸ªæ–¹æ³•é‡Œé¢å»åšçš„ã€‚`index_store`æœ¬æ¬¡ç¤ºä¾‹ä½¿ç”¨çš„Redisã€‚

`VectorStoreIndex`çš„`build_index_from_nodes`æ–¹æ³•å¦‚ä¸‹ï¼š

```python
    def build_index_from_nodes(
        self,
        nodes: Sequence[BaseNode],
        **insert_kwargs: Any,
    ) -> IndexDict:
        """Build the index from nodes.

        NOTE: Overrides BaseIndex.build_index_from_nodes.
            VectorStoreIndex only stores nodes in document store
            if vector store does not store text
        """
        # raise an error if even one node has no content
        if any(
            node.get_content(metadata_mode=MetadataMode.EMBED) == "" for node in nodes
        ):
            raise ValueError(
                "Cannot build index from nodes with no content. "
                "Please ensure all nodes have content."
            )

        return self._build_index_from_nodes(nodes, **insert_kwargs)

```

é¦–å…ˆä¼šåˆ¤æ–­nodeæ˜¯å¦æœ‰contentï¼Œå¦‚æœæ²¡æœ‰å°±æŠ¥é”™ã€‚ç„¶åè°ƒç”¨`_build_index_from_nodes`æ–¹æ³•ã€‚

```python
 def _build_index_from_nodes(
        self,
        nodes: Sequence[BaseNode],
        **insert_kwargs: Any,
    ) -> IndexDict:
        """Build index from nodes."""
        index_struct = self.index_struct_cls()
        if self._use_async:
            tasks = [
                self._async_add_nodes_to_index(
                    index_struct,
                    nodes,
                    show_progress=self._show_progress,
                    **insert_kwargs,
                )
            ]
            run_async_tasks(tasks)
        else:
            self._add_nodes_to_index(
                index_struct,
                nodes,
                show_progress=self._show_progress,
                **insert_kwargs,
            )
        return index_struct
```

é»˜è®¤æƒ…å†µä¸‹æ˜¯ä½¿ç”¨åŒæ­¥çš„æ–¹å¼è°ƒç”¨ï¼Œæ‰€ä»¥ä¼šè°ƒç”¨`_add_nodes_to_index`æ–¹æ³•ã€‚

```python
    def _add_nodes_to_index(
        self,
        index_struct: IndexDict,
        nodes: Sequence[BaseNode],
        show_progress: bool = False,
        **insert_kwargs: Any,
    ) -> None:
        """Add document to index."""
        if not nodes:
            return

        for nodes_batch in iter_batch(nodes, self._insert_batch_size):
            nodes_batch = self._get_node_with_embedding(nodes_batch, show_progress)
            new_ids = self._vector_store.add(nodes_batch, **insert_kwargs)

            if not self._vector_store.stores_text or self._store_nodes_override:
                # NOTE: if the vector store doesn't store text,
                # we need to add the nodes to the index struct and document store
                for node, new_id in zip(nodes_batch, new_ids):
                    # NOTE: remove embedding from node to avoid duplication
                    node_without_embedding = node.copy()
                    node_without_embedding.embedding = None

                    index_struct.add_node(node_without_embedding, text_id=new_id)
                    self._docstore.add_documents(
                        [node_without_embedding], allow_update=True
                    )
            else:
                # NOTE: if the vector store keeps text,
                # we only need to add image and index nodes
                for node, new_id in zip(nodes_batch, new_ids):
                    if isinstance(node, (ImageNode, IndexNode)):
                        # NOTE: remove embedding from node to avoid duplication
                        node_without_embedding = node.copy()
                        node_without_embedding.embedding = None

                        index_struct.add_node(node_without_embedding, text_id=new_id)
                        self._docstore.add_documents(
                            [node_without_embedding], allow_update=True
                        )
```

é¦–å…ˆä¼šå°†`nodes`æŒ‰ç…§`_insert_batch_size`å¤„ç†æˆä¸åŒçš„batchï¼Œç„¶åå¯¹æ¯ä¸€ä¸ªbatchè¿›è¡Œæ“ä½œã€‚å…¶ä¸­`_get_node_with_embedding`å¯¹ä¸€ä¸ªbatchçš„nodesè°ƒç”¨embedding modelè¿›è¡Œå‘é‡åŒ–æ“ä½œã€‚ç„¶åè°ƒç”¨`self._vector_store.add(nodes_batch, **insert_kwargs)`å°†å‘é‡åŒ–åçš„`nodes`å†™å…¥åˆ°å‘é‡æ•°æ®åº“ä¸­ã€‚è¿™ä¸ªæ–¹æ³•ä¼šè¿”å›ä¸€ä¸ª`new_ids`ï¼Œè¡¨ç¤ºä¸€ä¸ªbatchçš„nodesåœ¨å‘é‡æ•°æ®åº“ä¸­çš„IDåˆ—è¡¨ã€‚æ¥ä¸‹æ¥ä¼šåˆ¤æ–­å‘é‡æ•°æ®åº“çš„`stores_text`å±æ€§å’Œ`_store_nodes_override`å‚æ•°ï¼Œå¦‚æœå‘é‡æ•°æ®åº“çš„`stores_text`ä¸ºFalseæˆ–è€…`_store_nodes_override`å‚æ•°ä¸ºTrueï¼Œå°±ä¼šæ‰§è¡Œifè¯­å¥ï¼Œå¦åˆ™å°±æ‰§è¡Œelseè¯­å¥ã€‚if è¯­å¥ä¸­ä¼šå°†nodeçš„embeddingå­—æ®µç½®ä¸º Noneï¼Œç„¶åå°†å…¶æ·»åŠ åˆ°Indexä¸­ã€‚index add_nodeçš„ä»£ç å¦‚ä¸‹ï¼š

```python
@dataclass
class IndexDict(IndexStruct):
    """A simple dictionary of documents."""

    # TODO: slightly deprecated, should likely be a list or set now
    # mapping from vector store id to node doc_id
    nodes_dict: Dict[str, str] = field(default_factory=dict)

    # TODO: deprecated, not used
    # mapping from node doc_id to vector store id
    doc_id_dict: Dict[str, List[str]] = field(default_factory=dict)

    # TODO: deprecated, not used
    # this should be empty for all other indices
    embeddings_dict: Dict[str, List[float]] = field(default_factory=dict)

    def add_node(
        self,
        node: BaseNode,
        text_id: Optional[str] = None,
    ) -> str:
        """Add text to table, return current position in list."""
        # # don't worry about child indices for now, nodes are all in order
        # self.nodes_dict[int_id] = node
        vector_id = text_id if text_id is not None else node.node_id
        self.nodes_dict[vector_id] = node.node_id

        return vector_id

```

indexä¸­çš„nodes_dictç»´æŠ¤äº†å‘é‡æ•°æ®åº“IDå’Œnode_idçš„ä¸€ä¸ªå…³ç³»ï¼Œåœ¨æœ¬ä¾‹ä¸­è¿™ä¸¤ä¸ªIDæ˜¯ä¸€æ ·çš„ï¼Œéƒ½æ˜¯node.node_idã€‚æœ€åè°ƒç”¨

```python
self._docstore.add_documents(
    [node_without_embedding], allow_update=True
)
```

å°†nodeä¿å­˜çš„docstoreä¸­ï¼Œåœ¨æœ¬ä¾‹ä¸­ä¸ºMongoDBã€‚

åœ¨MongoDBä¸­ä¼šå°†æ•°æ®ä¿å­˜åœ¨`docstore/data`ã€`docstore/metadata`ã€`docstore/ref_doc_info`ä¸‰ä¸ªcollectionä¸­ã€‚

å…¶ä¸­`docstore/data`ä¸­ä¿å­˜çš„æ ¼å¼å¦‚ä¸‹ï¼š

```json
{
  "_id": "b87e8f8b-e21a-4eca-a0b5-83e336bc6ace",
  "__data__": {
    "id_": "b87e8f8b-e21a-4eca-a0b5-83e336bc6ace",
    "embedding": null,
    "metadata": {
      "page_label": "5",
      "file_name": "æµ‹è¯•.pdf",
      "file_path": "æµ‹è¯•.pdf",
      "file_type": "application/pdf",
      "file_size": 462360,
      "creation_date": "2024-02-04",
      "last_modified_date": "2023-11-14"
    },
    "excluded_embed_metadata_keys": [
      "file_name",
      "file_type",
      "file_size",
      "creation_date",
      "last_modified_date",
      "last_accessed_date"
    ],
    "excluded_llm_metadata_keys": [
      "file_name",
      "file_type",
      "file_size",
      "creation_date",
      "last_modified_date",
      "last_accessed_date"
    ],
    "relationships": {},
    "text": "ã€Š\nçƒ­åŠ å·¥å·¥è‰º\nã€‹\n2016\nå¹´\n10\næœˆ ç¬¬\n45\nå· ç¬¬\n19\næœŸ\næ¾ç¼©å­”ç°è±¡\nï¼Œ\nå›¾\n7\næ˜¾ç¤ºäº†é“åˆé‡‘ç½©ç›–ä¼˜åŒ–å‰åå‰–é¢\nçš„ç¼©å­”åŒºåŸŸ\nã€‚\nç”±å›¾å¯è§\nï¼š\nä¼˜åŒ–åç¼©å­”åŒºåŸŸæ¶ˆå¤±\nï¼Œ\nç¼©å­”\næ¦‚ç‡æ˜¾è‘—é™ä½\nï¼Œ\né“¸ä»¶çš„è´¨é‡å¾—åˆ°æé«˜\nã€‚\n5\nç»“è®º\nï¼ˆ\n1\nï¼‰\né‡‡ç”¨\nBP\nç¥ç»ç½‘ç»œä¸\nGA\nç»“åˆå¯å¯¹å‹é“¸å·¥\nè‰ºå‚æ•°è¿›è¡Œä¼˜åŒ–\nï¼Œ\næ‰¾å‡ºä¸€ç»„é€‚åˆé›¶ä»¶çš„æœ€ä½³å·¥è‰ºå‚æ•°\nã€‚\nï¼ˆ\n2\nï¼‰\né€šè¿‡å·¥è‰ºå‚æ•°çš„ä¼˜åŒ–\nï¼Œ\nå¯ä»¥å°†é›¶ä»¶çš„å‡å›º\næ—¶é—´å‡å°‘\nï¼Œ\näºŒæ¬¡ææ™¶è‡‚é—´è·å‡å°\nï¼Œ\nå‡ºç°ç¼©æ¾ç¼©å­”çš„æ¦‚\nç‡é™ä½\nï¼Œ\næˆå‹è´¨é‡å¾—åˆ°æé«˜\nã€‚\nå‚è€ƒæ–‡çŒ®\nï¼š\n[1]\nèµµå†›\nï¼Œ\nå°¹ç¡•\nï¼Œ\næ­¦å‘å—\nï¼\nBP\nç¥ç»ç½‘ç»œåœ¨\nAZ91D\né•åˆé‡‘æŒ¤å‹é“¸é€ \nå·¥è‰ºä¸­çš„åº”ç”¨\n[J]\nï¼\nçƒ­åŠ å·¥å·¥è‰º\nï¼Œ\n2013\nï¼Œ\n42(7)\nï¼š\n46-48\nï¼\n[2]\nèµµå»ºå\nï¼Œ\né»„æƒ å…°\nï¼Œ\nå°¹å†¬æ¢…\nï¼Œ\nç­‰\nï¼\nåŸºäºç¥ç»ç½‘ç»œçš„æ³µä½“é“¸é€ è¿‡ç¨‹\næ•°å€¼æ¨¡æ‹Ÿçš„ä¼˜åŒ–ä¸åº”ç”¨\n[J]\nï¼\nçƒ­åŠ å·¥å·¥è‰º\nï¼Œ\n2010\nï¼Œ\n39 (23)\nï¼š\n53-58\nï¼\n[3]\nå°šå®ˆå¹³\nï¼Œ\né›·æ•\nï¼Œ\nè’¯è¡Œæˆ\nï¼\nåœŸç»“æ„ç³»ç»Ÿçš„éçº¿æ€§å‚æ•°åæ¼”ç ”ç©¶\n[J]\nï¼\næ¹–å—å¤§å­¦å­¦æŠ¥\nï¼š\nè‡ªç„¶ç§‘å­¦ç‰ˆ\nï¼Œ\n2008\nï¼\n[4]\nå¼ å¾·ä¸°\nï¼\nMATLAB\nç¥ç»ç½‘ç»œåº”ç”¨è®¾è®¡\n[M]\nï¼\nåŒ—äº¬\nï¼š\næœºæ¢°å·¥ä¸š\nå‡ºç‰ˆç¤¾\nï¼Œ\n2009\nï¼\n[5]\né›·è‹±æ°\nï¼Œ\nå¼ å–„æ–‡\nï¼Œ\næç»­æ­¦\nï¼Œ\nç­‰\nï¼\nMATLAB\né—ä¼ ç®—æ³•å·¥å…·ç®±åŠåº”\nç”¨\n[M]\nï¼\nè¥¿å®‰\nï¼š\nè¥¿å®‰ç”µå­ç§‘æŠ€å¤§å­¦å‡ºç‰ˆç¤¾\nï¼Œ\n2005\nï¼\n1.0\n0.9\n0.8\n0.7\n0.6\n0.5\n0.4\n0.3\n0.2\n0.1\n0.0\nå›¾\n7\nå‹é“¸ä»¶ç¼©å­”æ¦‚ç‡å›¾\nFig.7 Porosity probability of die casting\n(a)\nä¼˜åŒ–å‰\n(b)\nä¼˜åŒ–å\næ¦‚ç‡ç¼ºé™·\nå‚æ•°\n=0.1\næ¦‚ç‡ç¼ºé™·\nå‚æ•°\n=0.04\nå¯¹æ¯”\nã€‚\nå¯çœ‹å‡º\nï¼š\nâ‘ \næŠ—æ‹‰å¼ºåº¦ç»è¿‡ç¨€åœŸå¤„ç†ä¹‹åæ¯”æœªå¤„\nç†çš„å‡æœ‰æé«˜\nï¼Œ\nå¹³å‡å€¼æé«˜è¾¾\n7.05%\nï¼›\nâ‘¡\nä¼¸é•¿ç‡ç»è¿‡\nç¨€åœŸå¤„ç†ä¹‹åæ¯”æœªå¤„ç†çš„ä»…æœ€å¤§å€¼æŒå¹³\nï¼Œ\næœ€å°å€¼å’Œ\nå¹³å‡å€¼å‡æœ‰é™ä½\nï¼Œ\nå…¶ä¸­å¹³å‡å€¼é™ä½\n12.82%\nï¼›\nâ‘¢\nå†²å‡»\nåŠŸç»è¿‡ç¨€åœŸå¤„ç†ä¹‹åæ¯”æœªå¤„ç†çš„å‡æœ‰é™ä½\nï¼Œ\nå¹³å‡å€¼\né™ä½è¾¾\n23.92%\nã€‚\n3\næ•°æ®åˆ†æ\nä¼—æ‰€å‘¨çŸ¥\nï¼Œ\né«˜é”°é’¢çš„é“¸æ€ç»„ç»‡æ˜¯ç”±å¥¥æ°ä½“\nã€\nç¢³åŒ–\nç‰©\nã€\nç å…‰ä½“å’Œå°‘é‡ç£·å…±æ™¶ç­‰ç»„æˆçš„\nã€‚\nç”±äºç¢³åŒ–ç‰©æ•°é‡\nå¤š\nï¼Œ\nå¹¶åœ¨æ™¶ç•Œå½¢æˆç½‘çŠ¶\nï¼Œ\nä¸¥é‡é™ä½é’¢çš„æ™¶ç•Œå¼ºåº¦\nï¼Œ\nä½¿\né’¢çš„æ€§èƒ½å˜è„†\nï¼Œ\nä¸€èˆ¬æƒ…å†µä¸‹ä¸èƒ½ä½¿ç”¨\nã€‚\nåªæœ‰é€šè¿‡å›ºæº¶å¤„ç†\nï¼ˆ\nå³æ°´éŸ§å¤„ç†\nï¼‰\nå\nï¼Œ\nä½¿é’¢ä¸­çš„ç¢³åŒ–ç‰©æº¶è§£äºå¥¥æ°\nä½“ä¸­\nï¼Œ\næˆä¸ºå•ä¸€çš„å¥¥æ°ä½“ç»„ç»‡\nï¼Œ\né«˜é”°é’¢æ‰å…·æœ‰è¾ƒé«˜çš„\nå¼ºåº¦\nã€\nå¡‘å½¢å’ŒéŸ§æ€§\nã€‚\nç¨€åœŸå…ƒç´ å¯¹é«˜é”°é’¢åŠ›å­¦æ€§èƒ½çš„å½±å“æ˜¯é’¢ä¸­éé‡‘\nå±å¤¹æ‚ç‰©\nã€\nç¢³åŒ–ç‰©\nã€\næ™¶ç²’åº¦ç­‰å„ç§å› ç´ ç»¼åˆå½±å“çš„ç»“\næœ\nã€‚\nç»¼åˆé‡‘ç›¸\nã€\næ‰«æç”µé•œå’ŒåŠ›å­¦æ€§èƒ½çš„æ£€æµ‹æ•°æ®\nï¼Œ\nåˆ†\næè®¤ä¸º\nï¼š\nåŠ å…¥ç¨€åœŸå…ƒç´ \nï¼Œ\nåˆ©ç”¨å…¶å…·æœ‰æ¯”è¾ƒé«˜çš„è¡¨é¢æ´»\næ€§ä»¥åŠç”±å®ƒå½¢æˆé«˜ç†”ç‚¹åŒ–åˆç‰©ä½œä¸ºç»“æ™¶æ ¸å¿ƒçš„ä½œ\nç”¨\nï¼Œ\nå› æ­¤ä¸€æ¬¡ç»“æ™¶å¾—åˆ°äº†ç»†åŒ–\nã€‚\nç»è¿‡ç¨€åœŸå¤„ç†åçš„\né«˜é”°é’¢\nï¼Œ\næ™¶ç²’åº¦æ˜æ˜¾ç»†åŒ–\nã€‚\nä½†å¿…é¡»æŒ‡å‡º\nï¼Œ\nç”±äºç¨€åœŸå…ƒ\nç´ ä¸é’¢ä¸­ç¢³å…ƒç´ å¯ä»¥å½¢æˆé«˜ç†”ç‚¹çš„ç¨€åœŸç¢³åŒ–ç‰©\nï¼Œ\nå®ƒ\nè™½ç„¶å­˜åœ¨äºæ™¶å†…\nï¼Œ\nä½†æ˜¯å¯¹é’¢çš„éŸ§æ€§å´äº§ç”Ÿä¸åˆ©å½±å“\nï¼Œ\nä½¿é«˜é”°é’¢æŠ—æ‹‰å¼ºåº¦æé«˜\nï¼Œ\nä½†ä½æ¸©å†²å‡»éŸ§æ€§é™ä½\nï¼Œ\nå³å†²\nå‡»å€¼ä¸‹é™\nï¼Œ\nç‰¹åˆ«æ˜¯åœ¨å¯’å†·åœ°åŒºä¼šè¡¨ç°å¾—æ›´åŠ æ˜æ˜¾\nã€‚\n4\nç»“è¯­\né«˜é”°é’¢é‡‡ç”¨ç¨€åœŸå¤„ç†\nï¼ˆ\nå³åŠ å…¥é’¢åŒ…å†…å¯¹é«˜é”°é’¢è¿›\nè¡Œå˜è´¨å¤„ç†\nï¼‰ï¼Œ\nå¯ä»¥æœ‰æ•ˆç»†åŒ–æ™¶ç²’\nï¼Œ\næŠ—æ‹‰å¼ºåº¦å¯ä»¥æé«˜\n7%\nå·¦å³\nï¼Œ\nä½†å†²å‡»å€¼å°†å¤§å¹…é™ä½\nï¼Œ\né™å¹…è¾¾\n23%\nã€‚\nåœ¨æ²¡æœ‰\nä½¿ç”¨ç²¾ç‚¼æŠ€æœ¯çš„æƒ…å†µä¸‹\nï¼Œ\nå†²å‡»å€¼ä¸‹é™éš¾ä»¥å…‹æœ\nã€‚\nå‚è€ƒæ–‡çŒ®\nï¼š\n[1]\néœæ–‡éœ\nï¼\nä¸åŒç¨€åœŸåŠ å…¥é‡å¯¹é«˜é”°é’¢ç»„ç»‡åŠåŠ›å­¦æ€§èƒ½çš„å½±å“\n[J]\nï¼\nçƒ­åŠ å·¥å·¥è‰º\nï¼Œ\n2012\nï¼Œ\n41(7)\nï¼š\n15-17\nï¼\n[2]\næ¨Šå®‰å›½\nï¼\nå¾®åˆé‡‘åŒ–çº¯å‡€é’¢ä¸­ç¨€åœŸå…ƒç´ çš„ä½œç”¨\n[J]\nï¼\næœ‰è‰²é‡‘å±\nï¼Œ\n2010\nï¼Œ\n62(1)\nï¼š\n14-16\nï¼\n[3]\né©¬ æ°\nï¼\nç¨€åœŸå…ƒç´ åœ¨é’¢ä¸­çš„ä½œç”¨åŠå¯¹é’¢æ€§èƒ½çš„å½±å“\n[J]\nï¼\né’¢é“\nç ”ç©¶\nï¼Œ\n2009\nï¼Œ\n37(3)\nï¼š\n54-56\nï¼\næ–¹æ¡ˆæ˜¯å¦åŠ å…¥ç¨€åœŸ\n(\nè¯•ä»¶ç¼–å·\n)\nR\nm\n/MPa\nA\n(%)\na\nU2\n/(J\nÂ·\ncm\n-2\n)\næ–¹æ¡ˆä¸€\næ–¹æ¡ˆäºŒ\næ–¹æ¡ˆä¸‰\nå¦\nï¼ˆ\n1A\nï¼‰\næ˜¯\nï¼ˆ\n1B\nï¼‰\nå¦\nï¼ˆ\n2A\nï¼‰\næ˜¯\nï¼ˆ\n2B\nï¼‰\nå¦\nï¼ˆ\n3A\nï¼‰\næ˜¯\nï¼ˆ\n3B\nï¼‰\n847\n943\n815\n892\n873\n87970.0\n70.5\n56.5\n48.5\n70.0\n52.5331\nï¼Œ\n288\nï¼Œ\n375\nï¼Œ\nå¹³å‡\n387.3\n456\nï¼Œ\n325\nï¼Œ\n325\nï¼Œ\nå¹³å‡\n312.6\n338\nï¼Œ\n281\nï¼Œ\n413\nï¼Œ\nå¹³å‡\n371.3\n363\nï¼Œ\n306\nï¼Œ\n325\nï¼Œ\nå¹³å‡\n304\n381\nï¼Œ\n275\nï¼Œ\n387\nï¼Œ\nå¹³å‡\n383\n381\nï¼Œ\n256\nï¼Œ\n225\nï¼Œ\nå¹³å‡\n252\nè¡¨\n4\nåŠ å…¥ç¨€åœŸå’ŒæœªåŠ ç¨€åœŸé«˜é”°é’¢çš„åŠ›å­¦æ€§èƒ½å¯¹æ¯”\nTab.4 The mechanical properties contrast of high\nmanganese steel with the rare earths and without the\nrare earths\nè¡¨\n3\nä¸åŒè¯•éªŒæ–¹æ¡ˆä¸‹é«˜é”°é’¢çš„åŠ›å­¦æ€§èƒ½æµ‹è¯•ç»“æœ\nTab.3 Mechanics performance test results of high\nmanganese steel under different test schemes\nè¯•éªŒæ–¹æ¡ˆ\nR\nm\n/MPa\nA\n(%)\na\nU2\n/(J\nÂ·\ncm\n-2\n)\næœ€å¤§å€¼æœ€å°å€¼å¹³å‡å€¼æœ€å¤§å€¼æœ€å°å€¼å¹³å‡å€¼æœ€å¤§å€¼æœ€å°å€¼å¹³å‡å€¼\næœªåŠ ç¨€åœŸ\nåŠ å…¥ç¨€åœŸ\n873\n943815\n879845\n904.670.0\n70.556.5\n48.565.5\n57.1387.3\n312.6371.3\n252380.5\n289.5\n(\nä¸Šæ¥ç¬¬\n117\né¡µ\n)\n119\n",
    "start_char_idx": null,
    "end_char_idx": null,
    "text_template": "{metadata_str}\n\n{content}",
    "metadata_template": "{key}: {value}",
    "metadata_seperator": "\n",
    "class_name": "Document"
  },
  "__type__": "4"
}
```

åœ¨`docstore/metadata`ä¸­çš„æ ¼å¼å¦‚ä¸‹ï¼š

```json
{
  "_id": "891af491-2999-4d99-b587-87a72a79af27",
  "doc_hash": "fa47aff1ecab93260fdba2a6c926bafd4d2cc0afcd2b4832b7ee092d3c2ed3f3"
}
```

åœ¨Redisä¸­å­˜å‚¨çš„indexæœ‰3ä¸ªå­—æ®µï¼Œåˆ†åˆ«æ˜¯IDï¼ŒKeyï¼ŒValueã€‚IDæ˜¯è‡ªå¢çš„æ•°å­—ï¼ŒKeyæ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œè¡¨ç¤ºç´¢å¼•IDï¼Œæ˜¯ä¸€ä¸ªUUIDæ ¼å¼ï¼ŒValueæ˜¯ä¸€ä¸ªå­—å…¸ï¼Œè¡¨ç¤ºLlamaIndexä¸­çš„ç´¢å¼•æ•°æ®ç»“æ„ã€‚æ ¼å¼å¦‚ä¸‹ï¼š

```json
{
    "__type__": "vector_store",
    "__data__": "{\"index_id\": \"a289e79a-6acc-4142-bf21-aeb9c16977bc\", \"summary\": null, \"nodes_dict\": {\"da98496b-27a1-4509-bdef-63fb9d834ea5\": \"da98496b-27a1-4509-bdef-63fb9d834ea5\", \"b77f422d-e51a-41a9-8c67-4b37f6d044ae\": \"b77f422d-e51a-41a9-8c67-4b37f6d044ae\", \"fa3932cd-7d81-4617-8c49-4c87607641cf\": \"fa3932cd-7d81-4617-8c49-4c87607641cf\", \"397947bb-5385-4078-b2ca-d86d7bf2003a\": \"397947bb-5385-4078-b2ca-d86d7bf2003a\", \"b87e8f8b-e21a-4eca-a0b5-83e336bc6ace\": \"b87e8f8b-e21a-4eca-a0b5-83e336bc6ace\"}, \"doc_id_dict\": {}, \"embeddings_dict\": {}}"
}
```

å…¶ä¸­ç»´æŠ¤äº†å‘é‡æ•°æ®åº“IDå’Œnode_idçš„å¯¹åº”å…³ç³»ã€‚
