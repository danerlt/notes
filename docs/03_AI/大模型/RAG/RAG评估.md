## RAG 评估常见的4个指标说明

以下是四个指标（**忠实度**、**召回率**、**答案相关性**、**上下文精度**）的详细说明，包括目标、实现方法、公式、公式说明、应用场景和示例：

---

### 1. **忠实度（Faithfulness）**
- **目标**：评估生成答案是否忠实于给定的上下文，避免生成与上下文无关或矛盾的内容（即“幻觉”问题）。
- **实现方法**：
  - 将生成答案拆分为多个句子。
  - 使用大语言模型（LLM）判断每个句子是否可以从上下文中直接推断出来。
- **公式**：
  \[
  \text{Faithfulness} = \frac{\text{忠实句子数量}}{\text{总句子数量}}
  \]
- **公式说明**：
  - **忠实句子数量**：生成答案中可以从上下文中直接推断出来的句子数量。
  - **总句子数量**：生成答案中所有句子的总数。
  - **意义**：衡量生成答案中有多少内容是与上下文一致的，避免生成与上下文无关或矛盾的内容。
- **应用场景**：问答系统、文本生成等任务，确保生成的答案不会“编造”信息。
- **示例**：
  - **上下文**：“爱因斯坦是德国出生的物理学家，他提出了相对论。”
  - **生成答案**：“爱因斯坦是德国出生的物理学家，他提出了光电效应。”
  - **分析**：
    - “爱因斯坦是德国出生的物理学家” → 忠实（1）。
    - “他提出了光电效应” → 不忠实（0）。
  - **得分**：\( \frac{1}{2} = 0.5 \)。

---

### 2. **召回率（Context Recall）**
- **目标**：评估生成答案是否覆盖了上下文中所有相关信息，避免遗漏重要信息。
- **实现方法**：
  - 将上下文拆分为多个关键信息点。
  - 使用大语言模型（LLM）判断每个信息点是否被包含在生成答案中。
- **公式**：
  \[
  \text{Recall} = \frac{\text{被包含的信息点数量}}{\text{总信息点数量}}
  \]
- **公式说明**：
  - **被包含的信息点数量**：生成答案中覆盖的上下文中关键信息点的数量。
  - **总信息点数量**：上下文中所有关键信息点的总数。
  - **意义**：衡量生成答案是否覆盖了上下文中所有重要信息，避免遗漏关键内容。
- **应用场景**：信息检索、文档摘要等任务，确保答案的完整性。
- **示例**：
  - **上下文**：“爱因斯坦是德国出生的物理学家，他提出了相对论和光电效应。”
  - **生成答案**：“爱因斯坦是德国出生的物理学家，他提出了相对论。”
  - **分析**：
    - “爱因斯坦是德国出生的物理学家” → 覆盖（1）。
    - “他提出了相对论” → 覆盖（1）。
    - “他提出了光电效应” → 未覆盖（0）。
  - **得分**：\( \frac{2}{3} \approx 0.67 \)。

---

### 3. **答案相关性（Answer Relevancy）**
- **目标**：评估生成答案是否与问题相关，避免生成模糊或不相关的答案。
- **实现方法**：
  - 使用大语言模型（LLM）为生成答案生成多个问题。
  - 计算生成问题与原始问题的余弦相似度。
  - 判断生成答案是否为非承诺性（如“我不知道”）。
- **公式**：
  \[
  \text{Relevancy} = \text{mean}(\text{cosine\_similarity}(q, g)) \times (1 - \text{noncommittal})
  \]
- **公式说明**：
  - **\(\text{cosine\_similarity}(q, g)\)**：生成问题 \(g\) 与原始问题 \(q\) 的余弦相似度，计算公式为：
    \[
    \text{cosine\_similarity}(q, g) = \frac{q \cdot g}{\|q\| \cdot \\|g\\|}
    \]
    其中，\(q\) 和 \(g\) 分别是原始问题和生成问题的嵌入向量。
  - **\(\text{mean}(\text{cosine\_similarity}(q, g))\)**：生成问题与原始问题的余弦相似度的平均值。
  - **\(\text{noncommittal}\)**：判断答案是否为非承诺性（如“我不知道”），如果是则为1，否则为0。
  - **意义**：衡量生成答案与问题的相关性，同时惩罚模糊或不相关的答案。
- **应用场景**：问答系统、文本生成等任务，确保答案与问题高度相关。
- **示例**：
  - **原始问题**：“爱因斯坦是谁？”
  - **生成答案**：“爱因斯坦是德国出生的物理学家。”
  - **生成问题**：“爱因斯坦的出生地是哪里？”
  - **余弦相似度**：0.9
  - **非承诺性判断**：0
  - **得分**：\( 0.9 \times (1 - 0) = 0.9 \)。

---

### 4. **上下文精度（Context Precision）**
- **目标**：评估上下文是否有助于生成答案，避免使用无关的上下文。
- **实现方法**：
  - 使用大语言模型（LLM）或非LLM方法（如嵌入相似度）判断每个上下文是否对生成答案有用。
  - 计算平均精度（Average Precision），衡量有用上下文的排名是否靠前。
- **公式**：
  \[
  \text{AP} = \frac{\sum_{i=1}^n \left(\frac{\sum_{j=1}^i \text{verdict}_j}{i}\right) \times \text{verdict}_i}{\sum_{i=1}^n \text{verdict}_i}
  \]
- **公式说明**：
  - **\(\text{verdict}_i\)**：第 \(i\) 个上下文的判断结果，1 表示有用，0 表示无用。
  - **\(\frac{\sum_{j=1}^i \text{verdict}_j}{i}\)**：前 \(i\) 个上下文的平均有用性。
  - **\(\sum_{i=1}^n \left(\frac{\sum_{j=1}^i \text{verdict}_j}{i}\right) \times \text{verdict}_i\)**：加权有用性总和，权重为前 \(i\) 个上下文的平均有用性。
  - **\(\sum_{i=1}^n \text{verdict}_i\)**：所有上下文中有用的总数。
  - **意义**：衡量有用上下文的排名是否靠前，确保模型优先使用有用的上下文。
- **应用场景**：信息检索、文档摘要等任务，确保上下文的有效性。
- **示例**：
  - **上下文1**：“爱因斯坦是德国出生的物理学家。”
  - **上下文2**：“爱因斯坦提出了相对论。”
  - **参考答案**：“爱因斯坦是德国出生的物理学家。”
  - **判断结果**：上下文1（1），上下文2（0）
  - **平均精度**：1.0

---

### 总结：
- **忠实度**：衡量生成答案与上下文的一致性，避免“幻觉”问题。
- **召回率**：衡量生成答案对上下文的覆盖程度，避免遗漏重要信息。
- **答案相关性**：衡量生成答案与问题的匹配程度，避免模糊或不相关的答案。
- **上下文精度**：衡量上下文的有效性和排名质量，确保优先使用有用的上下文。

这些指标结合使用，可以全面评估生成式模型在问答、文本生成和信息检索等任务中的表现。
