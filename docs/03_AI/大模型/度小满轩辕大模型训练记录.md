# 度小满轩辕大模型训练记录

## 环境搭建

具体可查看：[分布式训练环境搭建](分布式训练环境搭建.md)

### 运行环境

Nvidia显卡驱动版本: 535.154.05
CUDA版本: 12.2
Python版本:3.10.13
gcc版本:11.2.1

## 下载模型和数据集和项目

设置代理：

```bash
git config --global https.proxy http://127.0.0.1:10809
git config --global http.proxy http://127.0.0.1:10809
```

设置huggingface token:

```bash
# 安装huggingface_hub
pip install --upgrade huggingface_hub
# 登录huggingface, 打开 https://huggingface.co/settings/tokens 生成token，将生成的token粘贴到下面的命令的输入框
huggingface-cli login
```

![image-20240407093508139](https://danerlt-1258802437.cos.ap-chongqing.myqcloud.com/images/image-20240407093508139.png)

下载模型

```bash
cd /data/models
git clone https://huggingface.co/meta-llama/Llama-2-7b-hf.git
```

下载数据集

```bash
cd /data/datasets
git clone https://huggingface.co/datasets/Duxiaoman-DI/FinCorpus.git
```



## 训练

### 环境搭建

启用 GCC 11：

```bash
# 创建一个新session叫xy  xuanyuan的拼音首字母
screen -S xy
sudo scl enable devtoolset-11 bash
```

将`llm-code`目录下的`requirements.txt`文件先备份，然后将内容更新为下面的内容

```bash
argparse==1.4.0
datasets==2.16.1
transformers==4.37.1
sentencepiece==0.1.99
```

安装Python 依赖

```bash
pip install -r requirements.txt
```

安装 deepspeed 

```bash
# 编译 fuse_adam cpu_adam 并且加速编译
DS_BUILD_FUSED_ADAM=1   DS_BUILD_CPU_ADAM=1 pip install deepspeed==0.14.0 --global-option="build_ext" --global-option="-j96"
```

### 数据预处理

解压数据集

```bash
cd /data/datasets/FinCorpus
# 解压
gzip -d *.gz
```

修改预处理脚本

```bash
cd llm-code
vim data_preprocess_run.sh
```

修改路径,调整后的sh内容如下：

```bash
# Pretrain数据预处理
python3 pretrain_data_process.py \
    --model_name_or_path /data/models/Llama-2-7b-hf \
    --data_path /data/datasets/FinCorpus/data \
    --cache_dir ./cache/datasets \
    --save_dir ./data/FinCorpus_tokenized \
    --max_length 4096 \
    --num_proc 1024
```

执行数据预处理

```bash
sh data_preprocess_run.sh
```

报错`OSError: [Errno 24] Too many open files`

![image-20240408020939523](https://danerlt-1258802437.cos.ap-chongqing.myqcloud.com/images/image-20240408020939523.png)

执行下面的命令，将资源或进程数调大一点，或者将`data_preprocess_run.sh`中的`num_proc`调小一点：

```bash
ulimit -n 4096
```

执行结果如下：

![image-20240408033535715](https://danerlt-1258802437.cos.ap-chongqing.myqcloud.com/images/image-20240408033535715.png)

可以看出数据有一千两百万条数据。

![image-20240408082737528](https://danerlt-1258802437.cos.ap-chongqing.myqcloud.com/images/image-20240408082737528.png)

整个脚本运行花了大约4个小时。



### 预训练

使用两台服务器进行多机多卡训练，其中服务器 A 为 A100 （40G）* 2 , 服务器 B 为 V100 (32G) * 2。

添加`hostfile.txt`内容如下，`slots`表示服务器上有多少张显卡，这个参数需要保持一致。

```
服务器A的IP slots=2
服务器B的IP slots=2
```

调整预训练脚本，内容如下，路径改成实际的。

```bash
# Pretrain模型训练

# deepspped 参数说明
# --hostfile 多机多卡训练服务器IP和显卡配置

# dxm_llm_main.py参数说明
# --data_path 数据所在位置
# --model_name_or_path 模型文件位置
# --save_name 模型保存位置
# --learning_rate 学习率，默认为5e-5
# --weight_decay Weight decay，默认为0.01
# --num_warmup_steps lr scheduler的warmup步数
# --seed  随机种子
# --train_mode 训练模式：pretrain表示预训练任务，sft表示指令微调任务
# --epochs 指定训练轮数
# --total_num_steps 总训练步数
# --gradient_accumulation_steps 梯度累积步数
# --per_device_train_batch_size 每个GPU训练的Batch size
# --max_length 最大长度
# --gradient_checkpointing 是否开启梯度检查点，默认不开启。开启可节省GPU内存占用
# --log_steps 每隔多少步记录一次日志
# --save_steps 每隔多少步保存一次模型
# --ds_offload_cpu  是否开启cpu offload
# --ds_zero_stage deepspeed的zero配置
# --ds_steps_per_print 每隔多少步输出一次deepspeed日志
# --local_rank 多机多卡情况下的local_rank
# --global_rank 多机多卡情况下的global_rank
#

deepspeed \
    --hostfile hostfile.txt \
    dxm_llm_main.py \
    --data_path data/FinCorpus_tokenized \
    --model_name_or_path /data/models/Llama-2-7b-hf \
    --save_name model/model-pretrained \
    -train_mode pretrain \
    --epochs 1 \
    --per_device_train_batch_size 4 \
    --max_length 4096 \
    --ds_zero_stage 3 \
    --log_steps 2 \
    --save_steps 40 \
    --gradient_checkpointing
```

调整`llm-code`目录下的`config.py`，调整 ZeRO 参数如下：

```python
def get_deepspeed_config(args):
    ds_config = {
        "train_micro_batch_size_per_gpu":args.per_device_train_batch_size,  # 每个GPU的batch_size
        "gradient_accumulation_steps":args.gradient_accumulation_steps,  # 梯度累积步数
        "steps_per_print": args.ds_steps_per_print,  # deepspeed输出中间log
        "zero_optimization": {
            "stage": args.ds_zero_stage,  # 指定zero stage，可选0,1,2,3
        },
        "scheduler": {
            "type": "WarmupDecayLR",  # 学习率衰减策略
            "params": {
                "total_num_steps": args.total_num_steps,
                "warmup_min_lr": 0,
                "warmup_max_lr": args.learning_rate,
                "warmup_num_steps": args.num_warmup_steps
            }
        },
        "optimizer": {
            "type": "Adam",  # 优化器
            "params": {
                "lr": args.learning_rate,  # 学习率
                "weight_decay": args.weight_decay,  # 权重衰减
            }
        },
        "fp16": {
            "enabled": True,  # 开启fp16半精度训练，V100不支持BF16，所以使用FP16
            # 下面的参数来自 Lllama2-chinese
            "loss_scale": 0,
            "loss_scale_window": 1000,
            "initial_scale_power": 16,
            "hysteresis": 2,
            "min_loss_scale": 1,
            "fp16_opt_level": "O2"

        },
        "gradient_clipping": 1.0,  # 梯度裁剪
        "prescale_gradients": False,  # 是否在梯度更新前缩放梯度
        "wall_clock_breakdown": False,  # 是否输出deepspeed时间分析
    }
    if args.ds_zero_stage == 3:
        ds_config["zero_optimization"].update({
            "overlap_comm": True,
            "contiguous_gradients": True,
            "sub_group_size": 1e9,
            "reduce_bucket_size": "auto",
            "stage3_prefetch_bucket_size": "auto",
            "stage3_param_persistence_threshold": "auto",
            "stage3_max_live_parameters": 1e9,
            "stage3_max_reuse_distance": 1e9,
            "gather_16bit_weights_on_model_save": True,
            # ZeRO ++ 参数
            "zero_quantized_weights": True, # 是否使用量化零权重（qwZ）
            "zero_hpz_partition_size": 2, # hpZ（辅助分区）组中的Rank数，默认为1表示没有hpZ，理想的是每个节点的Rank数（GPU）
            "zero_quantized_gradients": True, # 是否使用量化零梯度（qgZ）
        })
    return ds_config

```





将服务器A作为主节点，要将模型和项目拷贝到服务器B节点。

首先在服务B上创建目录并修改权限：

```bash
mkdir -p /data/datasets
mkdir -p /data/models
chmod -R 766 /data/datasets
chmod -R 766 /data/models
```

在服务器A上执行拷贝模型，执行之前需要做SSH免密，SSH免密工作这里就不再赘述，可查看互联网上的教程，拷贝命令示例如下：

```bash
scp -rf /data/models/Llama-2-7b-hf root@服务器B的IP:/data/models
```

使用`rsync`工具同步项目代码，项目代码中包含了tokenizer之后的数据，`rsync`工具使用教程可参考: [rsync用法][1]

同步命令示例如下，需要将路径和IP换成实际的，注意`--exclude`要写相对路径，写绝对路径的话不生效。

```bash
rsync -avzh --delete \
--exclude 'llm-code/cache/*' \
--exclude '*.pyc' \
--exclude '.git/*' \
/data/workspace/XuanYuan root@服务器B的IP:/data/workspace/ \
```

我将同步的脚本放在了`llm-code`目录下的`sync.sh`中。

执行同步脚本：

```bash
bash sync.sh
```

运行报错`RuntimeError: [2] is setting up NCCL communicator and retrieving ncclUniqueId from [0] via c10d key-value store by key '0', but store->get('0') got error: Connection reset by peer. This may indicate a possible application crash on rank 0 or a network set up issue.`：

```
Loading checkpoint shards: 100%|██████████| 2/2 [00:18<00:00,  9.08s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:18<00:00,  9.02s/it]
10.168.144.5: Traceback (most recent call last):
10.168.144.5:   File "/data/litao/workspace/XuanYuan/llm-code/dxm_llm_main.py", line 197, in <module>
10.168.144.5:     main()
10.168.144.5:   File "/data/litao/workspace/XuanYuan/llm-code/dxm_llm_main.py", line 133, in main
10.168.144.5:     model = get_ds_model(args, dataloader_dict)
10.168.144.5:   File "/data/litao/workspace/XuanYuan/llm-code/dxm_llm_main.py", line 57, in get_ds_model
10.168.144.5:     model, _, _, lr_scheduler = deepspeed.initialize(
10.168.144.5:   File "/root/miniconda3/envs/dis/lib/python3.10/site-packages/deepspeed/__init__.py", line 176, in initialize
10.168.144.5:     engine = DeepSpeedEngine(args=args,
10.168.144.5:   File "/root/miniconda3/envs/dis/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 262, in __init__
10.168.144.5:     self._configure_distributed_model(model)
10.168.144.5:   File "/root/miniconda3/envs/dis/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 1157, in _configure_distributed_model
10.168.144.5:     self._broadcast_model()
10.168.144.5:   File "/root/miniconda3/envs/dis/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 1077, in _broadcast_model
10.168.144.5:     dist.broadcast(p.data, groups._get_broadcast_src_rank(), group=self.seq_data_parallel_group)
10.168.144.5:   File "/root/miniconda3/envs/dis/lib/python3.10/site-packages/deepspeed/comm/comm.py", line 117, in log_wrapper
10.168.144.5:     return func(*args, **kwargs)
10.168.144.5:   File "/root/miniconda3/envs/dis/lib/python3.10/site-packages/deepspeed/comm/comm.py", line 224, in broadcast
10.168.144.5:     return cdb.broadcast(tensor=tensor, src=src, group=group, async_op=async_op)
10.168.144.5:   File "/root/miniconda3/envs/dis/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 328, in _fn
10.168.144.5:     return fn(*args, **kwargs)
10.168.144.5:   File "/root/miniconda3/envs/dis/lib/python3.10/site-packages/deepspeed/comm/torch.py", line 205, in broadcast
10.168.144.5:     return torch.distributed.broadcast(tensor=tensor, src=src, group=group, async_op=async_op)
10.168.144.5:   File "/root/miniconda3/envs/dis/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 47, in wrapper
10.168.144.5:     return func(*args, **kwargs)
10.168.144.5:   File "/root/miniconda3/envs/dis/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 1910, in broadcast
10.168.144.5:     work = group.broadcast([tensor], opts)
10.168.144.5: RuntimeError: [2] is setting up NCCL communicator and retrieving ncclUniqueId from [0] via c10d key-value store by key '0', but store->get('0') got error: Connection reset by peer. This may indicate a possible application crash on rank 0 or a network set up issue.

```

看报错可能是由于修改了 hostname ,  ssh 免密出现问题，执行`ssh root@your_hostname` 之后再次训练报错：

```
10.113.75.134: [2024-04-09 18:31:50,463] [INFO] [logging.py:96:log_dist] [Rank 0] Using quantized gradients
10.113.75.134: Traceback (most recent call last):
10.113.75.134:   File "/data/litao/workspace/XuanYuan/llm-code/dxm_llm_main.py", line 197, in <module>
10.113.75.134:     main()
10.113.75.134:   File "/data/litao/workspace/XuanYuan/llm-code/dxm_llm_main.py", line 133, in main
10.113.75.134:     model = get_ds_model(args, dataloader_dict)
10.113.75.134:   File "/data/litao/workspace/XuanYuan/llm-code/dxm_llm_main.py", line 57, in get_ds_model
10.113.75.134:     model, _, _, lr_scheduler = deepspeed.initialize(
10.113.75.134:   File "/root/miniconda3/envs/dis/lib/python3.10/site-packages/deepspeed/__init__.py", line 176, in initialize
10.113.75.134:     engine = DeepSpeedEngine(args=args,
10.113.75.134:   File "/root/miniconda3/envs/dis/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 262, in __init__
10.113.75.134:     self._configure_distributed_model(model)
10.113.75.134:   File "/root/miniconda3/envs/dis/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 1157, in _configure_distributed_model
10.113.75.134:     self._broadcast_model()
10.113.75.134:   File "/root/miniconda3/envs/dis/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 1077, in _broadcast_model
10.113.75.134:     dist.broadcast(p.data, groups._get_broadcast_src_rank(), group=self.seq_data_parallel_group)
10.113.75.134:   File "/root/miniconda3/envs/dis/lib/python3.10/site-packages/deepspeed/comm/comm.py", line 117, in log_wrapper
10.113.75.134:     return func(*args, **kwargs)
10.113.75.134:   File "/root/miniconda3/envs/dis/lib/python3.10/site-packages/deepspeed/comm/comm.py", line 224, in broadcast
10.113.75.134:     return cdb.broadcast(tensor=tensor, src=src, group=group, async_op=async_op)
10.113.75.134:   File "/root/miniconda3/envs/dis/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 328, in _fn
10.113.75.134:     return fn(*args, **kwargs)
10.113.75.134:   File "/root/miniconda3/envs/dis/lib/python3.10/site-packages/deepspeed/comm/torch.py", line 205, in broadcast
10.113.75.134:     return torch.distributed.broadcast(tensor=tensor, src=src, group=group, async_op=async_op)
10.113.75.134:   File "/root/miniconda3/envs/dis/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 47, in wrapper
10.113.75.134:     return func(*args, **kwargs)
10.113.75.134:   File "/root/miniconda3/envs/dis/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 1910, in broadcast
10.113.75.134:     work = group.broadcast([tensor], opts)
10.113.75.134: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/NCCLUtils.hpp:219, invalid argument, NCCL version 2.14.3
10.113.75.134: ncclInvalidArgument: Invalid value for an argument.
10.113.75.134: Last error:
10.113.75.134: Invalid config blocking attribute value -2147483648
10.113.75.134: Traceback (most recent call last):
10.113.75.134:   File "/data/litao/workspace/XuanYuan/llm-code/dxm_llm_main.py", line 197, in <module>
10.113.75.134:     main()
10.113.75.134:   File "/data/litao/workspace/XuanYuan/llm-code/dxm_llm_main.py", line 133, in main
10.113.75.134:     model = get_ds_model(args, dataloader_dict)
10.113.75.134:   File "/data/litao/workspace/XuanYuan/llm-code/dxm_llm_main.py", line 57, in get_ds_model
10.113.75.134:     model, _, _, lr_scheduler = deepspeed.initialize(
10.113.75.134:   File "/root/miniconda3/envs/dis/lib/python3.10/site-packages/deepspeed/__init__.py", line 176, in initialize
10.113.75.134:     engine = DeepSpeedEngine(args=args,
10.113.75.134:   File "/root/miniconda3/envs/dis/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 262, in __init__
10.113.75.134:     self._configure_distributed_model(model)
10.113.75.134:   File "/root/miniconda3/envs/dis/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 1157, in _configure_distributed_model
10.113.75.134:     self._broadcast_model()
10.113.75.134:   File "/root/miniconda3/envs/dis/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 1077, in _broadcast_model
10.113.75.134:     dist.broadcast(p.data, groups._get_broadcast_src_rank(), group=self.seq_data_parallel_group)
10.113.75.134:   File "/root/miniconda3/envs/dis/lib/python3.10/site-packages/deepspeed/comm/comm.py", line 117, in log_wrapper
10.113.75.134:     return func(*args, **kwargs)
10.113.75.134:   File "/root/miniconda3/envs/dis/lib/python3.10/site-packages/deepspeed/comm/comm.py", line 224, in broadcast
10.113.75.134:     return cdb.broadcast(tensor=tensor, src=src, group=group, async_op=async_op)
10.113.75.134:   File "/root/miniconda3/envs/dis/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 328, in _fn
10.113.75.134:     return fn(*args, **kwargs)
10.113.75.134:   File "/root/miniconda3/envs/dis/lib/python3.10/site-packages/deepspeed/comm/torch.py", line 205, in broadcast
10.113.75.134:     return torch.distributed.broadcast(tensor=tensor, src=src, group=group, async_op=async_op)
10.113.75.134:   File "/root/miniconda3/envs/dis/lib/python3.10/site-packages/torch/distributed/c10d_logger.py", line 47, in wrapper
10.113.75.134:     return func(*args, **kwargs)
10.113.75.134:   File "/root/miniconda3/envs/dis/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py", line 1910, in broadcast
10.113.75.134:     work = group.broadcast([tensor], opts)
10.113.75.134: torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/NCCLUtils.hpp:219, invalid argument, NCCL version 2.14.3
10.113.75.134: ncclInvalidArgument: Invalid value for an argument.
10.113.75.134: Last error:
10.113.75.134: Invalid config blocking attribute value -2147483648
10.113.75.134: [2024-04-09 18:31:52,113] [INFO] [launch.py:316:sigkill_handler] Killing subprocess 42228
10.113.75.134: [2024-04-09 18:31:52,113] [INFO] [launch.py:316:sigkill_handler] Killing subprocess 42229
10.113.75.134: [2024-04-09 18:31:53,539] [ERROR] [launch.py:322:sigkill_handler] ['/root/miniconda3/envs/dis/bin/python', '-u', 'dxm_llm_main.py', '--local_rank=1', '--data_path', 'data/FinCorpus_tokenized', '--model_name_or_path', '/data/models/Llama-2-7b-hf', '--save_name', 'model/model-pretrained', '--train_mode', 'pretrain', '--epochs', '1', '--per_device_train_batch_size', '4', '--max_length', '4096', '--ds_zero_stage', '3', '--log_steps', '2', '--save_steps', '40', '--gradient_checkpointing'] exits with return code = 1

```





## 参考链接

- [1]: https://wangchujiang.com/linux-command/c/rsync.html	"rsync用法"