# 微调


## Qwen2-7B lora 微调
我们的项目命名为`sop`，提前构造好了微调的数据。

微调的数据格式示例如下：
```json
[
  {
    "instruction": "这是一个指令",
    "input": "这是输入",
    "output": "这是输出，我们的数据这里是一个Markdown格式的代码块，其中内容为JSON字符串"
  }
]
```

首先需要修改`LlamaFactory`项目的`data`目录下的`dataset_info.json`文件，将我们需要微调的数据集添加进去。

格式如下：

![](https://danerlt-1258802437.cos.ap-chongqing.myqcloud.com/images/20240715112738.png)

然后新建一个`sop`目录下，新建一个`qwen2_lora_sft.yaml`文件复制进去。

lora sft训练配置文件`qwen2_lora_sft.yaml`参数如下：

```yaml
### model
model_name_or_path: /data/models/Qwen2-7B

### method
stage: sft
do_train: true
finetuning_type: lora
lora_target: all

### dataset
dataset: sop
template: qwen
cutoff_len: 1024
max_samples: 10000
overwrite_cache: true
preprocessing_num_workers: 16

### output
output_dir: ./saves/qwen2-7b/lora/sft
logging_steps: 10
save_steps: 500
plot_loss: true
overwrite_output_dir: true

### train
per_device_train_batch_size: 1
gradient_accumulation_steps: 8
learning_rate: 1.0e-4
num_train_epochs: 3.0
lr_scheduler_type: cosine
warmup_ratio: 0.1
fp16: true
ddp_timeout: 180000000

### eval
val_size: 0.1
per_device_eval_batch_size: 1
eval_strategy: steps
eval_steps: 500
```

训练脚本`train.sh`内容：
```bash 
llamafactory-cli train sop/qwen2_lora_sft.yaml
```

执行训练的命令：
```bash
screen -S train

bash train.sh
```


9000条数据，A100 40G * 2 ，每个设备上的batch_size为1，1个epoch（500个Step）训练需要半个小时，总共3个epoch，训练用时为1个半小时。 训练时显存占用100%（40G）。


### 微调后的问题

- 模型微调后，模型过拟合，泛化能力差，对未见过的数据预测结果不好。
- 微调后，通用能力下降，输入普通的问题，如“中秋节吃什么”，输出结果会变成一个JSON，不符合预期。