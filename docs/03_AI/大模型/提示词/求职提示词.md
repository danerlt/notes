# 求职提示词

你是一个10年工作经验的Python工程师，精通Python开发和机器学习人工智能等领域。
我现在需要求职找工作，工作JD内容如下：

```text
岗位职责:
1.负责产品后台大模型服务设计与开发
2.负责后台数据库设计与架构;
3.负责后台核心模块代码重构和性能优化:
4.负责AI平台的开发和MaaS平台工程化。
岗位要求:
1.熟练使用 python编程语言，代码风格优雅，有完整项目开发经验；
2.熟练使用 git、docker、k8s等开发、构建、版本控制工具；
3.熟练掌握主流 web框架，diango、sanic、tornado等；
4.熟练使用常见的开源工具，包括nginx、redis、mongodb等；
5.熟练掌握常见的数据结构和算法；
6.良好的编写文档习惯，代码习惯，结构清晰，命名规范，逻辑性强;
7.熟悉微服务架构设计，掌握多线程并发编程以及性能调优；
8.能独立解决项目难点，或可提出可行方案；
9.善于思考，能独立分析和解决问题，积极主动；
10.有langchain等Agent框架开发经验者优先；
11.对人工智能感兴趣，有银行项目或系统开发经验者优先。
```

我会给你一些我的工作内容，你需要按照招聘JD帮我优化： 

工作内容如下：
````markdown
一个基于检索增强生成（RAG）技术和大语言模型的垂直领域知识库问答系统。现在系统已经上线使用，根据用户反馈，能解决用户80%左右的问题。

- **技术选型和架构设计**：

  - 设计RAG系统架构，主要分为数据加载、分片、构建索引、检索、提示词模板、大模型对话、RAG评估等核心模块。
  - 对比Langchain框架和LlamaIndex框架的功能和适用场景，最终选择基于Langchain框架实现RAG中数据加载和分片模块，基于LlamaIndex实现构建索引、检索、提示词、大模型对话、RAG评估模块。
  - 对比传统数据库和向量数据库特性，最终选择Qdrant存储向量数据，使用MongoDB存储分片后的文档，使用PostgreSQL存储服务相关的数据库表。

  **RAG技术全流程的开发**：

  - 加载模块：基于Langchain框架实现文档加载模块。

  - 分片模块：对比LangChain框架和LlamaIndex框架的多种分片策略，选择合适的分片策略。并对markdown、csv、excel格式的文件进行了优化。
  - 构建索引：
    - 基于LlamaIndex框架构建索引，并对其索引结构进行优化，只需要使用MongoDB存储文档，使用Qdrant存储向量数据。去掉了index_store，减少了检索链路，提高了检索效率。
    - embeding模型优化：从beg-base切换到m3e-bse再到微调bge-base。
  - 检索：
    - 检索主要分为组合检索和单一检索两大类，组合检索可以将多个检索器的结果根据合并策略合并起来，再进行检索后处理。单一检索器有分为检索前、检索中、检索后3个步骤。
    - 检索前主要实现了HyDE,MultiQuestion等查询转换。
    - 检索中实现了向量数据库相似度检索和BM25算法检索。
    - 检索后实现了去重、使用rerank model重排、根据平均值过滤、使用Kmeans算法过滤等方法。
    - 组合检索实现了Extend合并、求交集、Fusion算法合并等方法。
    - 将检索模块各种方法排列组合成25+种检索策略，并通过RAG评估找的检索效果最好的策略。
  - 提示词模板：
    - 运用角色扮演、COT、few-show等提示词工程技术对提示词进行优化。
  - 大模型对话：
    - 对比chatglm3-6b、qwen1.5-7b、qwen1.5-14B等模型推理效果，结合显存资源使用qwen1.5-14B作为基座大模型。
    - 使用FastChat和vllm模块部署大语言模型到生成环境
  - RAG评估：
    - LlamaIndex框架只支持对一种策略进行评估，使用进程池和队列对多种策略进行评估。最终测试下来使用组合检索（BM25和向量数据库）加上重排和平均值过滤的策略可以使检索效果最好。
  - 多轮对话优化：
    - 使用意图识别提升用户输入不明确的场景的回答效果。
    - 使用根据历史信息重写问题提升多轮对话的回答效果。

- **Web服务**：

  - 使用Flask技术栈和Gunicorn、Docker、Docker Compose等工具搭建知识库PythonWeb服务。开发数据集管理、文件管理，对话管理的RESTful API。
  - 使用Docker-compose管理PostgreSQL、Redis、Qrant、MinIO、MongoDB等中间件。

- **模型训练、部署**：

  - 利用FastChat、vllm、Docker-compose等工具将LLM、embedding、rerank模型部署到生产环境。
  - 使用Deepspeed、LlamaFactory和Docker，搭建大语言模型分布式训练和微调的环境。
  - 验证了Atom-7B、XuanYuan-7B、Llama2-7B的二次预训练和微调过程。


````