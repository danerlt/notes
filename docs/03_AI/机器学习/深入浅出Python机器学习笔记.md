# 深入浅出Python机器学习笔记

## 机器学习中的概念

Q:什么是有监督学习？
A：有监督学习是指在训练过程中，我们给模型提供的数据既包括输入数据，也包括正确的输出数据，也就是标签。模型的任务就是学习如何从输入数据预测出正确的输出。常见的有监督学习任务有分类（例如，判断一封邮件是垃圾邮件还是非垃圾邮件）和回归（例如，预测房价）。

Q:什么是无监督学习？
A：无监督学习则是指在训练过程中，我们只给模型提供输入数据，不提供正确的输出数据。模型的任务是自我学习数据的结构或者分布。常见的无监督学习任务有数据转换和聚类分析。最常见的数据转换方法之一是数据降维，通过对特征变量较多的数据集进行分析，将无关的特征变量去除，保留关键特征。聚类算法将样本划到不同的分组，每个分组的元素都有接近的特征。

Q:有监督学习和无监督学习的区别？应用方面有什么不同？
A：两者的主要区别在于，有监督学习的训练数据包含了正确答案，而无监督学习的训练数据没有包含正确答案。 在应用方面，有监督学习通常用于标签已知的预测任务，例如垃圾邮件分类、房价预测等；而无监督学习通常用于探索性的数据分析，例如用户分群、主题建模等，或者在标签不易获取的情况下对数据进行预处理或降维。

|            | 有监督学习                                                   | **无监督学习**                                               |
| ---------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 它是什么？ | 可以使用一组输入数据和一组相应的已标记配对输出数据来训练模型。 | 可以训练模型以发现未标记数据中的隐藏模式。                   |
| 技术       | 逻辑回归、线性回归、决策树和神经网络。                       | 集群、关联规则学习、概率密度和降维。                         |
| 目标       | 根据已知输入预测输出。                                       | 识别输入数据点之间有价值的关系信息。然后，可以将此信息应用于新的输入，以得出类似的见解。 |
| 方法       | 最大限度地减少预测输出和真实标签之间的误差。                 | 查找数据中的模式、相似性或异常。                             |

Q:什么是分类，什么是回归，各自的应用场景有哪些？
A：分类和回归是有监督学习中最常见的任务。

|          | **分类**                                       | 回归                                           |
| -------- | ---------------------------------------------- | ---------------------------------------------- |
| 定义     | 分类是预测离散标签的任务，输出是离散的类别。   | 回归是预测连续值的任务，输出是一个连续的数值。 |
| 应用场景 | 二分类（垃圾邮件识别）、多分类（手写数字识别） | 房价预测、股票价格预测                         |


Q:什么是模型的泛化？
A：在有监督学习中，在训练集上会建立一个模型，之后会把这个模型用于新的数据中进行预测，这个过程叫做模型的泛化（generalization）。

Q:什么过拟合，什么是欠拟合，它们是如何出现的，如何避免过拟合和欠拟合？
A：模型在训练集上表现良好，但是在测试集上表现不好，就叫做过拟合（overfitting）。模型在训练集和测试集上表现都不好叫做欠拟合（underfitting）。

避免过拟合的方法：

- 数据扩增：通过对原有训练数据进行一些变换（如旋转、缩放、裁剪等）来生成新的训练样本，增大训练集的大小。
- 正则化：在模型训练过程中加入一些额外的约束，例如L1和L2正则化，来限制模型的复杂度。
- 早停：在模型的验证集误差不再减小或者开始增大时，停止模型的训练，防止模型过度拟合训练数据。
- 集成学习：训练多个模型然后综合他们的预测结果，可以有效地防止过拟合。
- Dropout：在神经网络中，随机忽略一些神经元的输出，可以防止模型过度依赖某些特征，从而防止过拟合。

避免欠拟合的方法：

- 增加模型复杂度：如果模型过于简单，无法捕捉到数据的分布，可以尝试增加模型的复杂度，例如增加神经网络的层数或者神经元的数量。
- 特征工程：对原始特征进行一些转换或者提取新的特征，可能会帮助模型更好地捕捉到数据的规律。
- 减小正则化项：如果模型过于简单，可能是正则化项的惩罚过大，可以尝试减小正则化项的系数。
- 调整模型训练时间：模型训练时间过短，可能导致模型还未能学习到数据的规律。可以尝试增加模型的训练时间。

## 常用的算法

### K近邻算法
> k近邻算法（k-Nearest Neighbors，简称k-NN）是一种基于实例的学习，或者说是一种基于记忆的学习。

#### 原理
找到距离新样本最近的k个训练样本，然后让这k个训练样本中出现最多的类别作为新样本的预测类别。

#### 用途

#### 特性

#### 表现如何

#### 如何建模

#### 模型的参数如何调整

### 线性模型
#### 原理
#### 用途
#### 特性
#### 表现如何
#### 如何建模
#### 模型的参数如何调整

### 朴素贝叶斯
#### 原理
#### 用途
#### 特性
#### 表现如何
#### 如何建模
#### 模型的参数如何调整

### 决策树
#### 原理
#### 用途
#### 特性
#### 表现如何
#### 如何建模
#### 模型的参数如何调整

### 随机森林
#### 原理
#### 用途
#### 特性
#### 表现如何
#### 如何建模
#### 模型的参数如何调整

### SVM
#### 原理
#### 用途
#### 特性
#### 表现如何
#### 如何建模
#### 模型的参数如何调整

### 神经网络
#### 原理
#### 用途
#### 特性
#### 表现如何
#### 如何建模
#### 模型的参数如何调整


## 数据处理
### 数据降维
### 数据聚类

## 模型优化
### 提高算法的效率
### 怎样找到最合适的模型
### 模型最优的参数是什么
### 如何打造一个流水线
